{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1759e421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as tp\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d2556e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "JAN_DATA = \"data/fhv_tripdata_2021-01.parquet\"\n",
    "FEB_DATA = \"data/fhv_tripdata_2021-02.parquet\"\n",
    "\n",
    "\n",
    "jan_data = pd.read_parquet(JAN_DATA)\n",
    "feb_data = pd.read_parquet(FEB_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48df4ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataframe(raw_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    data = raw_data.copy()\n",
    "    \n",
    "    # Translate data columns to datetimes.\n",
    "    data[\"pickup_datetime\"] = pd.to_datetime(data[\"pickup_datetime\"])\n",
    "    data[\"dropOff_datetime\"] = pd.to_datetime(data[\"dropOff_datetime\"])\n",
    "    \n",
    "    # Compute duration time in minutes.\n",
    "    data[\"duration\"] = (data[\"dropOff_datetime\"] - data[\"pickup_datetime\"]).dt.total_seconds() / 60\n",
    "    \n",
    "    # Filter data by duration.\n",
    "    data = data.query(\"duration >= 1 and duration <= 60\")\n",
    "    assert (data[\"duration\"] >= 1).all() and (data[\"duration\"] <= 60).all()\n",
    "    \n",
    "    # Fill NaN's.\n",
    "    data[\"PUlocationID\"] = data[\"PUlocationID\"].fillna(-1).astype(int).astype(str)\n",
    "    data[\"DOlocationID\"] = data[\"DOlocationID\"].fillna(-1).astype(int).astype(str)\n",
    "    assert not data[\"DOlocationID\"].isna().all() and not data[\"PUlocationID\"].isna().all()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c91df6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xz/lh8h89515p57_vpg0mgc_ddc0000gn/T/ipykernel_80042/4277040427.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"PUlocationID\"] = data[\"PUlocationID\"].fillna(-1).astype(int).astype(str)\n",
      "/var/folders/xz/lh8h89515p57_vpg0mgc_ddc0000gn/T/ipykernel_80042/4277040427.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"DOlocationID\"] = data[\"DOlocationID\"].fillna(-1).astype(int).astype(str)\n",
      "/var/folders/xz/lh8h89515p57_vpg0mgc_ddc0000gn/T/ipykernel_80042/4277040427.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"PUlocationID\"] = data[\"PUlocationID\"].fillna(-1).astype(int).astype(str)\n",
      "/var/folders/xz/lh8h89515p57_vpg0mgc_ddc0000gn/T/ipykernel_80042/4277040427.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"DOlocationID\"] = data[\"DOlocationID\"].fillna(-1).astype(int).astype(str)\n"
     ]
    }
   ],
   "source": [
    "jan_data = prepare_dataframe(jan_data)\n",
    "feb_data = prepare_dataframe(feb_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d7a648b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Design matrix dims: (1109826, 525)\n",
      "Design matrix dims: (990113, 525)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "\n",
    "def fit_vectorizer(data: pd.DataFrame, categorical_features: list[str]) -> DictVectorizer:\n",
    "    dv = DictVectorizer()\n",
    "    train_dicts = data[categorical_features].to_dict(orient=\"records\")\n",
    "    dv.fit(train_dicts)\n",
    "    return dv\n",
    "\n",
    "\n",
    "def get_x_and_y(\n",
    "    data: pd.DataFrame,\n",
    "    categorical_features: list[str],\n",
    "    vectorizer: DictVectorizer,\n",
    ") -> tuple[np.ndarray, np.ndarray]:\n",
    "    dicts = data[categorical_features].to_dict(orient=\"records\")\n",
    "    X = vectorizer.transform(dicts)\n",
    "    print(\"Design matrix dims:\", X.shape)\n",
    "    y = data[\"duration\"].values\n",
    "    return X, y\n",
    "\n",
    "\n",
    "vectorizer = fit_vectorizer(jan_data, categorical_features=[\"DOlocationID\", \"PUlocationID\"])\n",
    "X_train, y_train = get_x_and_y(jan_data, categorical_features=[\"DOlocationID\", \"PUlocationID\"], vectorizer=vectorizer)\n",
    "X_test, y_test = get_x_and_y(feb_data, categorical_features=[\"DOlocationID\", \"PUlocationID\"], vectorizer=vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1e392e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 10.52851942175949, val: 11.014286819428976\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def train_and_validate(\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    "    X_val: np.ndarray,\n",
    "    y_val: np.ndarray\n",
    ") -> tuple[float, float]:\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    train_score = mean_squared_error(y_train, lr.predict(X_train), squared=False)\n",
    "    val_score = mean_squared_error(y_val, lr.predict(X_val), squared=False)\n",
    "    return train_score, val_score\n",
    "\n",
    "\n",
    "print(\"Train: {}, val: {}\".format(*train_and_validate(X_train, y_train, X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1834ae8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
